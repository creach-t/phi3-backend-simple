# Phi-3 Backend Simple

Backend simplifiÃ© pour interface de chat Phi-3 avec authentification JWT, gestion de modÃ¨les et systÃ¨me d'inscription complet.

## âœ¨ FonctionnalitÃ©s

- âœ… **Authentification JWT complÃ¨te** avec inscription/connexion
- âœ… **Gestion de modÃ¨les** (tÃ©lÃ©chargement, activation, suppression)
- âœ… **Service llama.cpp** intÃ©grÃ© avec gÃ©nÃ©ration de rÃ©ponses
- âœ… **SystÃ¨me de preprompts** avec gestion CRUD
- âœ… **Base de donnÃ©es SQLite** simple et efficace
- âœ… **API RESTful** claire et documentÃ©e
- âœ… **Validation des donnÃ©es** avec Joi
- âœ… **SÃ©curitÃ©** avec Helmet et rate limiting
- âœ… **CORS** configurÃ©
- âœ… **TypeScript** pour la robustesse

## ğŸš€ Installation

```bash
# Cloner le repository
git clone https://github.com/creach-t/phi3-backend-simple.git
cd phi3-backend-simple

# Installer les dÃ©pendances
npm install

# Copier le fichier d'environnement
cp .env.example .env

# Ã‰diter le fichier .env avec vos paramÃ¨tres
nano .env
```

## âš™ï¸ Configuration

Ã‰ditez le fichier `.env` avec vos paramÃ¨tres :

```bash
# Serveur
PORT=3000
NODE_ENV=development

# JWT
JWT_SECRET=votre-super-secret-jwt-key-tres-securisee
JWT_EXPIRES_IN=86400

# Base de donnÃ©es
DB_PATH=./database.sqlite

# CORS
CORS_ORIGIN=http://localhost:3001

# llama.cpp et Phi-3
LLAMA_CPP_PATH=/path/to/llama.cpp/main
PHI3_MAX_TOKENS=2048
PHI3_TEMPERATURE=0.7
```

## ğŸ“‹ PrÃ©requis

1. **Node.js** 18+ et npm
2. **llama.cpp** compilÃ© sur votre systÃ¨me
3. **curl** pour le tÃ©lÃ©chargement de modÃ¨les

### Installation de llama.cpp

```bash
# Cloner et compiler llama.cpp
git clone https://github.com/ggerganov/llama.cpp.git
cd llama.cpp
make

# Mettre Ã  jour le chemin dans .env
LLAMA_CPP_PATH=/path/to/llama.cpp/main
```

## ğŸ¯ DÃ©marrage

```bash
# Mode dÃ©veloppement avec rechargement automatique
npm run dev

# Build et dÃ©marrage en production
npm run build
npm start
```

## ğŸ”— API Endpoints

### ğŸ” Authentification
- `POST /api/auth/register` - Inscription
- `POST /api/auth/login` - Connexion
- `GET /api/auth/me` - Profil utilisateur (authentifiÃ©)
- `POST /api/auth/logout` - DÃ©connexion

### ğŸ’¬ Chat
- `POST /api/chat` - Envoyer un message au modÃ¨le
- `POST /api/chat/stop` - ArrÃªter la gÃ©nÃ©ration en cours
- `GET /api/chat/status` - Statut du modÃ¨le
- `POST /api/chat/test` - Test de connexion llama.cpp

### ğŸ¤– Gestion des modÃ¨les
- `GET /api/models` - Lister tous les modÃ¨les
- `POST /api/models/download` - TÃ©lÃ©charger un modÃ¨le depuis Hugging Face
- `POST /api/models/activate` - Activer un modÃ¨le
- `DELETE /api/models/:filename` - Supprimer un modÃ¨le
- `GET /api/models/downloads` - Statut des tÃ©lÃ©chargements
- `POST /api/models/downloads/:id/cancel` - Annuler un tÃ©lÃ©chargement

### ğŸ“ Preprompts
- `GET /api/preprompts` - Lister tous les preprompts
- `GET /api/preprompts/default` - Obtenir le preprompt par dÃ©faut
- `GET /api/preprompts/:id` - Obtenir un preprompt spÃ©cifique
- `POST /api/preprompts` - CrÃ©er un nouveau preprompt
- `PUT /api/preprompts/:id` - Modifier un preprompt
- `DELETE /api/preprompts/:id` - Supprimer un preprompt
- `POST /api/preprompts/:id/set-default` - DÃ©finir comme dÃ©faut

### ğŸ©º SantÃ©
- `GET /health` - VÃ©rification de l'Ã©tat du serveur
- `GET /api/` - Informations sur l'API

## ğŸ“ Structure du projet

```
src/
â”œâ”€â”€ controllers/         # Logique mÃ©tier
â”‚   â”œâ”€â”€ auth.controller.ts
â”‚   â”œâ”€â”€ chat.controller.ts
â”‚   â”œâ”€â”€ model.controller.ts
â”‚   â””â”€â”€ preprompt.controller.ts
â”œâ”€â”€ middleware/         # Middlewares Express
â”‚   â”œâ”€â”€ auth.middleware.ts
â”‚   â””â”€â”€ error.middleware.ts
â”œâ”€â”€ routes/            # DÃ©finition des routes
â”‚   â”œâ”€â”€ auth.routes.ts
â”‚   â”œâ”€â”€ chat.routes.ts
â”‚   â”œâ”€â”€ model.routes.ts
â”‚   â”œâ”€â”€ preprompt.routes.ts
â”‚   â””â”€â”€ index.ts
â”œâ”€â”€ services/          # Services mÃ©tier
â”‚   â”œâ”€â”€ database.service.ts
â”‚   â”œâ”€â”€ llama.service.ts
â”‚   â”œâ”€â”€ model.service.ts
â”‚   â”œâ”€â”€ phi3.service.ts
â”‚   â””â”€â”€ preprompt.service.ts
â”œâ”€â”€ types/             # Types TypeScript
â”‚   â”œâ”€â”€ auth.types.ts
â”‚   â”œâ”€â”€ chat.types.ts
â”‚   â””â”€â”€ common.types.ts
â”œâ”€â”€ utils/             # Utilitaires
â”‚   â”œâ”€â”€ jwt.ts
â”‚   â”œâ”€â”€ logger.ts
â”‚   â””â”€â”€ validation.ts
â”œâ”€â”€ app.ts             # Configuration Express
â””â”€â”€ server.ts          # Point d'entrÃ©e
```

## ğŸ”§ Utilisation

### 1. TÃ©lÃ©charger un modÃ¨le

```bash
curl -X POST http://localhost:3000/api/models/download \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_JWT_TOKEN" \
  -d '{
    "url": "https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-q4.gguf"
  }'
```

### 2. Activer un modÃ¨le

```bash
curl -X POST http://localhost:3000/api/models/activate \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_JWT_TOKEN" \
  -d '{"filename": "Phi-3-mini-4k-instruct-q4.gguf"}'
```

### 3. Envoyer un message

```bash
curl -X POST http://localhost:3000/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Salut, comment Ã§a va ?",
    "prepromptId": "preprompt_id_optional",
    "modelParams": {
      "temperature": 0.7,
      "maxTokens": 2048
    }
  }'
```

## ğŸ› DÃ©pannage

### Erreur "llama.cpp not found"
- VÃ©rifiez que `LLAMA_CPP_PATH` pointe vers l'exÃ©cutable llama.cpp compilÃ©
- Testez manuellement : `/path/to/llama.cpp/main --help`

### Erreur "Model not found"
- VÃ©rifiez qu'un modÃ¨le est activÃ© : `GET /api/models`
- Les modÃ¨les sont stockÃ©s dans le dossier `models/`

### ProblÃ¨mes de tÃ©lÃ©chargement
- VÃ©rifiez que `curl` est installÃ©
- Les URLs doivent Ãªtre des liens directs vers des fichiers .gguf depuis Hugging Face

## ğŸ“„ Licence

MIT

---

**Note**: Ce backend est simplifiÃ© mais complet. Toutes les fonctionnalitÃ©s de l'ancien systÃ¨me sont prÃ©sentes dans une architecture plus claire et maintenable.